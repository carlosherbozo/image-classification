{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                     transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                     transforms.RandomResizedCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
    "# transforms.Normalize((0.5,0.5), (0.5,0.5)),\n",
    "\n",
    "train = datasets.ImageFolder(train_dir,transform=train_transforms)\n",
    "valid = datasets.ImageFolder(valid_dir,transform=test_transforms)\n",
    "test = datasets.ImageFolder(test_dir,transform=test_transforms)\n",
    "\n",
    "train_load = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True)\n",
    "valid_load = torch.utils.data.DataLoader(valid, batch_size=64)\n",
    "test_load = torch.utils.data.DataLoader(test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "print(len(cat_to_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "hidden_size = 512\n",
    "output_size=102\n",
    "input_size=25088\n",
    "#224*224\n",
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "vgg16.classifier=nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_size)),\n",
    "                      ('drop', nn.Dropout(p = 0.5)),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_size, output_size)),\n",
    "                      ('softmax', nn.LogSoftmax(dim=1))]))\n",
    "#\n",
    "criterion=nn.NLLLoss()\n",
    "LR=0.001\n",
    "optimizer = optim.Adam(vgg16.classifier.parameters(), lr = LR)\n",
    "\n",
    "epochs=3\n",
    "vgg16.class_to_idx = train.class_to_idx\n",
    "batch_size=64\n",
    "vgg16.cuda()\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    print(e)\n",
    "    i=1\n",
    "    for images, labels in train_load:\n",
    "        images=images.cuda()\n",
    "        labels=labels.cuda()\n",
    "        #= images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = vgg16.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Still running\",round(64*i/len(train),2)*100,\"%\")\n",
    "        i+=1\n",
    "        running_loss += loss.item()\n",
    "        #if i==10:\n",
    "        #    break\n",
    "    valid_loss=0\n",
    "    acc=0\n",
    "    vgg16.eval()\n",
    "    i=1\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_load:\n",
    "            images=images.cuda()\n",
    "            labels=labels.cuda()\n",
    "            #images, labels = images.to(device), labels.to(device)\n",
    "            output=vgg16.forward(images)\n",
    "            loss=criterion(output,labels)\n",
    "            valid_loss+=loss.item()\n",
    "            ps= torch.exp(output)\n",
    "            top_p, top_class = ps.topk(1, dim = 1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            acc+= torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            #if i==10:\n",
    "            #    break\n",
    "    vgg16.train()\n",
    "    print(f\"Training loss: {running_loss/len(train_load)}\")\n",
    "    print(f\"Accuracy: {acc / len(valid_load)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss=0\n",
    "acc=0\n",
    "vgg16.eval()\n",
    "i=1\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_load:\n",
    "        images=images.cuda()\n",
    "        labels=labels.cuda()\n",
    "        #images, labels = images.to(device), labels.to(device)\n",
    "        output=vgg16.forward(images)\n",
    "        loss=criterion(output,labels)\n",
    "        valid_loss+=loss.item()\n",
    "        ps= torch.exp(output)\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        acc+= torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        #if i==10:\n",
    "        #    break\n",
    "vgg16.train()\n",
    "print(f\"Training loss: {running_loss/len(train_load)}\")\n",
    "print(f\"Accuracy: {acc / len(valid_load)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.class_to_idx = train.class_to_idx\n",
    "batch_size=64\n",
    "checkpoint = {'network': 'vgg16',\n",
    "              'input_size': input_size,\n",
    "              'output_size': output_size,\n",
    "              'learning_rate': LR,       \n",
    "              'batch_size': batch_size,\n",
    "              'classifier' :vgg16.classifier,\n",
    "              'epochs': epochs,\n",
    "              'optimizer': optimizer.state_dict(),\n",
    "              'state_dict': vgg16.state_dict(),\n",
    "              'class_to_idx': vgg16.class_to_idx}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(file_path):\n",
    "    checkpoint = torch.load(file_path)\n",
    "    LR = checkpoint['learning_rate']\n",
    "    model = getattr(models, checkpoint['network'])(pretrained=True)\n",
    "    model.classifier = checkpoint['classifier']\n",
    "    model.epochs = checkpoint['epochs']\n",
    "    model.optimizer = checkpoint['optimizer']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    return model\n",
    "\n",
    "vgg16 = load_checkpoint('checkpoint.pth')\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    i_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(244), \n",
    "                                     transforms.ToTensor(),])\n",
    "    np_image = np.array(i_transform(image).float())\n",
    "\n",
    "    np_image=(np.transpose(np_image,(1,2,0))-np.array([0.485,0.456,0.406]))/np.array([0.229,0.224,0.225])\n",
    "    np_image = np.transpose(np_image, (2, 0, 1))\n",
    "    return(np_image)\n",
    "\n",
    "import PIL\n",
    "import os\n",
    "import numpy as np\n",
    "ldir=os.listdir(train_dir+\"/1\")\n",
    "image= PIL.Image.open(train_dir+\"/1/image_06735.jpg\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    #image = image.numpy().transpose((1, 2, 0))\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "imshow(process_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    image = PIL.Image.open(image_path)\n",
    "    np_image=process_image(image)\n",
    "    tensor_image=torch.from_numpy(np_image).unsqueeze_(0).float().cuda()\n",
    "    logp = model.forward(tensor_image)\n",
    "    prob = torch.exp(logp)    \n",
    "    top_p, top_classes = prob.topk(topk, dim = 1)\n",
    "    idx = {model.class_to_idx[c]: c for c in model.class_to_idx}\n",
    "    top_c=[cat_to_name[idx[l]] for l in  top_classes.cpu().detach().numpy()[0]]\n",
    "\n",
    "    return(top_p.cpu().detach().numpy()[0],top_c)\n",
    "im_path=train_dir+\"/1/image_06735.jpg\"\n",
    "top_p,top_c=predict(im_path,vgg16)\n",
    "print(top_p)\n",
    "print(top_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "ax1 = plt.subplot2grid((15,9), (0,0), colspan = 9, rowspan = 9)\n",
    "ax2 = plt.subplot2grid((15,9), (9,2), colspan = 5, rowspan = 5)\n",
    "\n",
    "ax1.axis('off')\n",
    "ax1.set_title(top_c[np.argmax(top_p)])\n",
    "ax1.imshow(image)\n",
    "\n",
    "\n",
    "y_pos = np.arange(5)\n",
    "ax2.set_yticks(y_pos)\n",
    "ax2.set_yticklabels(top_c)\n",
    "ax2.set_xlabel('Probability')\n",
    "ax2.invert_yaxis()\n",
    "ax2.barh(y_pos, top_p, xerr = 0, align = 'center', color = 'blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    ldir=os.listdir(train_dir+\"/\"+str(i+1))\n",
    "    im_path=train_dir+\"/\"+str(i+1)+\"/\"+ldir[i]\n",
    "    print(im_path)\n",
    "    top_p,top_c=predict(im_path,vgg16)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax1 = plt.subplot2grid((15,9), (0,0), colspan = 9, rowspan = 9)\n",
    "    ax2 = plt.subplot2grid((15,9), (9,2), colspan = 5, rowspan = 5)\n",
    "\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(top_c[np.argmax(top_p)])\n",
    "    image = PIL.Image.open(im_path)\n",
    "    ax1.imshow(image)\n",
    "\n",
    "\n",
    "    y_pos = np.arange(5)\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(top_c)\n",
    "    ax2.set_xlabel('Probability')\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.barh(y_pos, top_p, xerr = 0, align = 'center', color = 'blue')\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
